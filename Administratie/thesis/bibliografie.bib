@article{Fang2003,
abstract = {In a visual driver-assistance system, road-sign detection and tracking is one of the major tasks. This study describes an approach to detecting and tracking road signs appearing in complex traffic scenes. In the detection phase, two neural networks are developed to extract color and shape features of traffic signs from the input scenes images. Traffic signs are then located in the images based on the extracted features. This process is primarily conceptualized in terms of fuzzy-set discipline. In the tracking phase, traffic signs located in the previous phase are tracked through image sequences using a Kalman filter. The experimental results demonstrate that the proposed method performs well in both detecting and tracking road signs present in complex scenes and in various weather and illumination conditions.},
annote = {Zoekt naar edges en spesifieke hue apart. Voegt daarna deze 2 samen en vergelijkt dit met mogelijke boden},
author = {Fang, Chiung Yao and Chen, Sei Wang and Fuh, Chiou Shann},
doi = {10.1109/TVT.2003.810999},
isbn = {0018-9545},
issn = {00189545},
journal = {IEEE Transactions on Vehicular Technology},
keywords = {(HSI) color model,Fuzzy integration,Hue,Intensity,Kalman filter,Neural networks,Road-sign detection and tracking,Saturation},
number = {5},
pages = {1329--1341},
title = {{Road-sign detection and tracking}},
volume = {52},
year = {2003}
}
@article{Zabihi2017,
author = {Zabihi, S. J. and Zabihi, S. M. and Beauchemin, S. S. and Bauer, M. A.},
doi = {10.1109/IVS.2017.7995781},
isbn = {9781509048045},
issn = {0022-4596},
journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
number = {Iv},
pages = {583--588},
title = {{Detection and recognition of traffic signs inside the attentional visual field of drivers}},
year = {2017}
}
@inproceedings{Lowe1999,
author = {Lowe, D G},
booktitle = {Proceedings of the Seventh IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.1999.790410},
month = {sep},
pages = {1150--1157 vol.2},
title = {{Object recognition from local scale-invariant features}},
volume = {2},
year = {1999}
}
@article{zhangwall,
  title={Wall, Floor, Ceiling, Object Region Identification from Single Image},
  author={Zhang, Zhong-Ju},
  publisher={Citeseer}
}
@article{Li2010,
abstract = {We present a novel method for image-based floor detection from a single image. In contrast with previous approaches that rely upon homographies, our approach does not require multiple images (either stereo or optical flow). It also does not require the camera to be calibrated, even for lens distortion. The technique combines three visual cues for evaluating the likelihood of horizontal intensity edge line segments belonging to the wall-floor boundary. The combination of these cues yields a robust system that works even in the presence of severe specular reflections, which are common in indoor environments. The nearly real-time algorithm is tested on a large database of images collected in a wide variety of conditions, on which it achieves nearly 90{\%} detection accuracy.},
author = {Li, Yinxiao and Birchfield, Stanley T.},
doi = {10.1109/IROS.2010.5652818},
isbn = {9781424466757},
issn = {2153-0858},
journal = {IEEE/RSJ 2010 International Conference on Intelligent Robots and Systems, IROS 2010 - Conference Proceedings},
pages = {837--843},
title = {{Image-based segmentation of indoor corridor floors for a mobile robot}},
year = {2010}
}
@article{Redmon_2016,
   title={You Only Look Once: Unified, Real-Time Object Detection},
   ISBN={9781467388511},
   url={http://dx.doi.org/10.1109/CVPR.2016.91},
   DOI={10.1109/cvpr.2016.91},
   journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
   publisher={IEEE},
   author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
   year={2016},
   month={Jun}
}
@ARTICLE{Canny, 
author={J. Canny}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={A Computational Approach to Edge Detection}, 
year={1986}, 
volume={PAMI-8}, 
number={6}, 
pages={679-698}, 
keywords={Image edge detection;Detectors;Machine vision;Shape measurement;Performance analysis;Uncertainty;Gaussian approximation;Signal to noise ratio;Signal synthesis;Feature extraction;Edge detection;feature extraction;image processing;machine vision;multiscale image analysis}, 
doi={10.1109/TPAMI.1986.4767851}, 
ISSN={0162-8828}, 
month={Nov},}

@article{Rodriguez-Telles2013,
abstract = {We present a novel technique that robustly segments free-space for robot navigation purposes. In particular, we are interested in a reactive visual navigation, in which the rapid and accurate detection of free space where the robot can navigate is crucial. Contrary to existing methods that use multiple cameras in different configurations, we use a downward-facing monocular camera to search for free space in a large and complicated room environment. The proposed approach combines two techniques. First, we apply the Simple Linear Iterative Clustering super-pixel algorithm to the input images. Then, by relying on particular characteristics of floor super pixels, we use a simple classification method based on a normalized SSD similarity measure to group together those super pixels that belongs to the floor (considered as free space). The method intermittently examines low resolution images (80 × 60) in the CIE Lab color model. Experimental results show that our segmentation approach is robust, even in the presence of severe specular reflections and allows for real-time navigation. {\textcopyright} 2013 IEEE.},
author = {Rodr{\'{i}}guez-Telles, F. Geovani and Torres-M{\'{e}}ndez, L. Abril and Mart{\'{i}}nez-Garc{\'{i}}a, Edgar A.},
doi = {10.1109/CRV.2013.40},
isbn = {9780769549835},
journal = {Proceedings - 2013 International Conference on Computer and Robot Vision, CRV 2013},
keywords = {SLIC superpixels,segmentation},
pages = {167--173},
title = {{A fast floor segmentation algorithm for visual-based robot navigation}},
year = {2013}
}
@ARTICLE{slic, 
author={R. Achanta and A. Shaji and K. Smith and A. Lucchi and P. Fua and S. Süsstrunk}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={SLIC Superpixels Compared to State-of-the-Art Superpixel Methods}, 
year={2012}, 
volume={34}, 
number={11}, 
pages={2274-2282}, 
keywords={computer vision;image segmentation;iterative methods;pattern clustering;SLIC superpixels;computer vision;image boundary;memory efficiency;segmentation performance;simple linear iterative clustering;k-means clustering approach;superpixel generation;supervoxel generation;Clustering algorithms;Image segmentation;Complexity theory;Image color analysis;Image edge detection;Measurement uncertainty;Approximation algorithms;Superpixels;segmentation;clustering;k-means;Algorithms;Image Enhancement;Image Interpretation, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted}, 
doi={10.1109/TPAMI.2012.120}, 
ISSN={0162-8828}, 
month={Nov},}

@article{Badrinarayanan,
archivePrefix = {arXiv},
arxivId = {arXiv:1511.00561v3},
author = {Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto and Member, Senior},
eprint = {arXiv:1511.00561v3},
pages = {1--14},
title = {{SegNet : A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation}}
}

@InProceedings{Song_2015_CVPR,
author = {Song, Shuran and Lichtenberg, Samuel P. and Xiao, Jianxiong},
title = {SUN RGB-D: A RGB-D Scene Understanding Benchmark Suite},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2015}
}