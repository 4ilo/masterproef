@article{Fang2003,
abstract = {In a visual driver-assistance system, road-sign detection and tracking is one of the major tasks. This study describes an approach to detecting and tracking road signs appearing in complex traffic scenes. In the detection phase, two neural networks are developed to extract color and shape features of traffic signs from the input scenes images. Traffic signs are then located in the images based on the extracted features. This process is primarily conceptualized in terms of fuzzy-set discipline. In the tracking phase, traffic signs located in the previous phase are tracked through image sequences using a Kalman filter. The experimental results demonstrate that the proposed method performs well in both detecting and tracking road signs present in complex scenes and in various weather and illumination conditions.},
annote = {Zoekt naar edges en spesifieke hue apart. Voegt daarna deze 2 samen en vergelijkt dit met mogelijke boden},
author = {Fang, Chiung Yao and Chen, Sei Wang and Fuh, Chiou Shann},
doi = {10.1109/TVT.2003.810999},
isbn = {0018-9545},
issn = {00189545},
journal = {IEEE Transactions on Vehicular Technology},
keywords = {(HSI) color model,Fuzzy integration,Hue,Intensity,Kalman filter,Neural networks,Road-sign detection and tracking,Saturation},
number = {5},
pages = {1329--1341},
title = {{Road-sign detection and tracking}},
volume = {52},
year = {2003}
}
@article{Zabihi2017,
author = {Zabihi, S. J. and Zabihi, S. M. and Beauchemin, S. S. and Bauer, M. A.},
doi = {10.1109/IVS.2017.7995781},
isbn = {9781509048045},
issn = {0022-4596},
journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
number = {Iv},
pages = {583--588},
title = {{Detection and recognition of traffic signs inside the attentional visual field of drivers}},
year = {2017}
}
@inproceedings{Lowe1999,
author = {Lowe, D G},
booktitle = {Proceedings of the Seventh IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.1999.790410},
month = {sep},
pages = {1150--1157 vol.2},
title = {{Object recognition from local scale-invariant features}},
volume = {2},
year = {1999}
}
@article{zhangwall,
  title={Wall, Floor, Ceiling, Object Region Identification from Single Image},
  author={Zhang, Zhong-Ju},
  publisher={Citeseer}
}
@article{Li2010,
abstract = {We present a novel method for image-based floor detection from a single image. In contrast with previous approaches that rely upon homographies, our approach does not require multiple images (either stereo or optical flow). It also does not require the camera to be calibrated, even for lens distortion. The technique combines three visual cues for evaluating the likelihood of horizontal intensity edge line segments belonging to the wall-floor boundary. The combination of these cues yields a robust system that works even in the presence of severe specular reflections, which are common in indoor environments. The nearly real-time algorithm is tested on a large database of images collected in a wide variety of conditions, on which it achieves nearly 90{\%} detection accuracy.},
author = {Li, Yinxiao and Birchfield, Stanley T.},
doi = {10.1109/IROS.2010.5652818},
isbn = {9781424466757},
issn = {2153-0858},
journal = {IEEE/RSJ 2010 International Conference on Intelligent Robots and Systems, IROS 2010 - Conference Proceedings},
pages = {837--843},
title = {{Image-based segmentation of indoor corridor floors for a mobile robot}},
year = {2010}
}
@article{Redmon_2016,
   title={You Only Look Once: Unified, Real-Time Object Detection},
   ISBN={9781467388511},
   url={http://dx.doi.org/10.1109/CVPR.2016.91},
   DOI={10.1109/cvpr.2016.91},
   journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
   publisher={IEEE},
   author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
   year={2016},
   month={Jun}
}

