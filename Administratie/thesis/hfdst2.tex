%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%                                                                 %
%                       LITERATUURSTUDIE                          %
%                                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\chapter{Literatuurstudie}

    \section{Indoor navigatie \& visie}
        Op visie gebaseerde navigatie is een onderwerp dat zeer vaak onderzocht wordt. Oudere onderzoeken zoals~\cite{Tomono2000} maken gebruik van een robot met een \gls{rgb} camera die zonder kaart informatie.
        De enige informatie die gegeven wordt is een eenvoudige object beschrijving van de gang en een beschrijving van een deur met een deurnummer ernaast.
        Met enkel een deurnummer als doel vertrekt de robot door de gang, en houd zichzelf parallel met de muren door gebruik te maken van andere sensoren. Eens er een deur in beeld komt, worden er een aantal features(randen)
        herkent in het beeld. Nadat de deuren herkend worden kan er via \gls{ocr} de deurnummer herkend worden en nagegaan of het doel bereikt is. Dit is uiteraard een zeer eenvoudige techniek omdat de robot geen begrip heeft van de omgeving, en moeilijk plaatsen t.o.v elkaar kan onderscheiden.

        Nieuwere technieken zoals~\cite{Henry10rgb-dmapping} maken gebruik van RGB-D camera's zoals bijvoorbeeld een kinect waardoor ze ook over diepte informatie beschikken. Die diepte info kan dan gebruikt worden om heel
        de omgeving in 3d te mappen en op basis van de effectief gemeten positie navigatie te doen. Een andere manier om een 3d representatie van de omgeving te verkrijgen zoals~\cite{schmid2013} is gebruik te maken van stereo visie.
        Hierbij wordt de informatie van 2 \gls{rgb} camera's die op een vaste afstand van elkaar staan gecombineerd om diepte informatie te verzamelen.

        In dit onderzoek gaan we ons echter beperken tot een enkele \gls{rgb} camera.
        
    \section{Object detectie}

        Een belangrijk aspect van dit onderzoek is het detecteren van individuele objecten in het beeld van 1 enkele \gls{rgb} camera.
        De te detecteren objecten zijn op voorhand vastgelegd, en zijn afhankelijk van de ruimte waarin de robot zich bevindt.

        In de logistieke gangen van een ziekenhuis zijn er heel wat objecten te zien die we kunnen detecteren, een kleine selectie van deze objecten zijn.

        \begin{itemize}
            \item Pictogrammen
            \item Brandblussers
            \item Deurklinken
        \end{itemize}

        Voor deze objecten gaan we kijken naar detectie technieken uit de traditionele beeldverwerking, en naar meer \textit{state of the art} technieken. 


        \subsection{Traditionele object detectie} \label{sec:trad_obj_det}
            In openbare gebouwen zijn er heel wat pictogrammen te vinden zoals nooduitgang, hoogspanning en brandblusser. Deze pictogrammen hebben steeds een specifieke vorm, kleur en symbool.
            De literatuur leert ons weinig over pictogramdetectie, maar pictogrammen kunnen wel vergeleken worden met verkeersborden die bijna dezelfde kenmerken hebben.
            De aanpak van~\cite{Fang2003} is om 2 soorten features in een beeld te onderscheiden. In eerste instantie detecteren ze vormen op basis van kleur randen en anderzijds wordt de
            afbeelding omgezet naar \gls{hsi} waaruit enkel de hue gebruikt wordt. De hue is de belangrijkste component voor het onderscheiden van kleuren omdat er zo geen rekening wordt gehouden
            met de hoeveelheid licht en schaduwen.
            Een recenter onderzoek~\cite{Zabihi2017} bouwt voort op deze technieken,
            maar berekenen de \gls{hog} features van het beeld. Vervolgens wordt er gebruik gemaakt van een \gls{svm} om te bepalen waar er zich een match bevindt.

            De vorm en kleur features kunnen dan gecombineerd worden om de plaats voor een mogelijke match te vinden. Eens er een mogelijke boundig box gevonden is,
            kan er geprobeerd worden een template te matchen om het effectieve pictogram te achterhalen. Het grootste probleem bij de techniek van~\cite{Fang2003} is
            dat hun gebruikte template matching techniek niet robuust is voor schaal invariantie.
            Bij~\cite{Zabihi2017} maken ze voor de herkenningsfase gebruik van \gls{sift}\cite{Lowe1999} features en kleur informatie.
            Hierdoor is het probleem van schaal invariantie grotendeels opgelost.
            Hierbij worden de \gls{sift} features van de kandidaat matches en de templates vergeleken, en er wordt een gemiddelde genomen van de verschillen tussen hue, saturation en value.
            Door middel van \gls{ransac} en een treshold wordt er bepaald welke matches gebruikt worden. Deze techniek zou gebruikt kunnen worden voor het detecteren van pictogrammen.

        
        \subsection{Convolutional neural nework} \label{sec:yolo}
            De laatste jaren in het domein van beeldverwerking wordt er steeds meer gegrepen naar deep learning technieken. Dit is komt omdat rekenkracht steeds beter en beter wordt, en de resultaten die bekomen worden
            de traditionele manieren overtreffen op verschillende vlakken. Een deep learning techniek die veel gebruikt wordt in de beeldverwerking is een \gls{cnn}.

            Een \gls{cnn} is een supervised deep learning techniek die gebruikt kan worden om complexere beeldinterpretatie te doen.
            Een \gls{cnn} kan bestaan uit meerdere lagen die meestal een combinatie zijn van 'convolutional-layers' en 'fully connected-layers'. Elk van deze lagen bevat een aantal neuronen met elk een eigen set van gewichten.
            Het doel van een \gls{cnn} is om de gewichten zodanig bij te stellen zodat data die aan de eerste laag gegeven wordt een verwacht resultaat geeft aan de laatste laag. 
            Deze laatste laag kan men de classificatielaag noemen, en geeft een representatie van wat het netwerk denkt dat er aan de input staat. In figuur~\ref{fig:yolo_cnn} is een voorbeeld tezien van een \gls{cnn} met de verschillende soorten lagen.

            \begin{figure}[!htb]
                \centering
                \includegraphics[width=0.75\linewidth]{yolo_cnn.jpeg}
                \caption{De lagen van een CNN volgens het YOLO~\cite{Redmon_2016} detection system.}
                \label{fig:yolo_cnn}
            \end{figure}

            Een 'convolutional-layer' is een laag die een convolutie operatie uitvoert op zijn input, de convolutie gebeurd d.m.v een masker dat meestal voorgesteld wordt als een tensor.
            Door een tensormasker te gebruiken kan de operatie uitgevoerd worden op meerdere inputdimensies tegelijkertijd, denk hierbij aan bijvoorbeeld 3 kleurkanalen.

            Om uiteindelijk een classificatie te verkrijgen moet er een dimensievermindering doorgevoerd te worden, dit wordt gedaan door 'pooling layers' aan het netwerk toe te voegen na elke convolutie laag. 

            Een CNN kan pas gebruikt worden nadat het getraind is. Voor de training van een netwerk zijn er 2 dingen noodzakelijk, veel voorbeeld data en per voorbeeld de verwachte output (label).
            Bij het trainingsproces wordt alle inputdata aangelegd, en wordt er gekeken wat het netwerk aan zijn output heeft.
            De loss functie is een maat van hoe goed een netwerk een voorspelling kan doen van de input data, met andere woorden een vergelijking tussen de input en de output. Het doel van de training van een netwerk is het minimaliseren
            van deze loss functie. Dit kan gedaan worden d.m.v 'backprogagation'. Backpropagation is het steeds een klein beetje aanpassen van de gewichten in de inwendige neuronen om zo het resultaat te verbeteren en de loss functie te verkleinen.
            Een netwerk heeft een goede training gehad als de loss functie minimaal is.

            Een voorbeeld van een CNN is het '\gls{yolo} detection system'~\cite{Redmon_2016}. Het \gls{yolo} netwerk is opgebouwd uit 24 convolutielagen en 2 fully connected layers.
            Dit netwerk heeft een uitgebreide training gehad op de ImageNet dataset en kan gebruikt worden om object detectie en classificatie te doen door 1 keer de input afbeelding door het netwerk te laten gaan.
            Door middel van een hertraining kan deze detector leren om alle objecten te detecteren en te classificeren en dus een mogelijke detector zijn voor onze toepassing.

            Zoals~\cite{Llopart2017} voorstelt is het niet moeilijk om het '\gls{yolo} detection system' een hertraining te geven om deuren te herkennen. Zo kan dit ook toegevoegd worden aan de lijst met te detecteren kenmerken. 


    \section{Object tracking}
        Object tracking of het volgen van objecten heeft als doel het bepalen van de positie van hetzelfde object over meerdere frames heen. In het geval van dit onderzoek kan het een indicatie geven van relatieve posities t.o.v. objecten die zich in de gangen bevinden.
        Een grote moeilijkheid bij het volgen van objecten stilstaan t.o.v. de camera is dat ze veranderen in grootte, ori\"{e}ntatie en perspectief.
        \cite{Zhou2009} stelt voor om gebruik te maken van \gls{sift} voor het volgen van objecten. Ze zoeken een \gls{roi} op het eerste frame waarop ze een kleurhistogram en \gls{sift} features berekenen.
        Op het volgende frame worden dezelfde bewerkingen uitgevoerd in een regio die net iets groter is dan de originele \gls{roi}. Een overeenkomst regio wordt dan berekend door middel van een \gls{em} algoritme.
        Volgens~\cite{Baheti2016} is het beter om gebruik te maken van het KLT feature algoritme~\cite{tomasi1991detection}. Hiermee wordt er een transformatie berekend waardoor de \gls{roi} tussen de 2 frames gelijkaardig wordt. De initi\"{e}le transformatieparameters worden berekend via \gls{ransac}.

        \cite{Ning2017} heeft een nieuwe techniek ontwikkeld om object tracking te combineren met object detectie \gls{cnn}. Ze hebben een uitbreiding gemaakt op het \gls{yolo} detection system genaamd \gls{rolo}.
        De uitbreiding bevat een extra \gls{lstm} geplaatst achter de detectie fase van het originele netwerk. Een \gls{lstm} is een neuraal netwerk geoptimaliseerd voor het maken van beslissingen op tijds gebaseerde data.
        De data die aan het extra netwerk gegeven wordt is een van de tussenresultaten van het \gls{yolo} netwerk.
        Het systeem blijkt zeer goed te werken voor het volgen van objecten zelfs bij occlusies in 1 van de beelden. 

    \section{Image segmentation}\label{sec:image_segmentation}
        Het correct segmenteren van de beelden zal een belangrijke rol spelen. Niet in elk beeld zal er een distinctief object aanwezig zijn om te detecteren. Daarom is het belangrijk om de vloer van
        de muren te kunnen onderscheiden. Een eenvoudige aanpak zou kunnen zijn om via K-means een verdeling van een beeld te doen en met een soort regressie de regio's te labelen. 
        Volgens~\cite{zhangwall} werkt de K-means aanpak met een op textuur en kleur gebaseerde aanpak redelijk goed, maar wordt steeds de muur verbonden met het plafond omwille van kleur en textuur gelijkenissen.
        Hun regressie gebaseerde labeling techniek blijkt echter een slechte oplossing. Verder zoals~\cite{Li2010} aangeeft zijn reflecties en overbelichting eigenschappen van indoor omgevingen die het moeilijk kunnen maken om
        een correcte segmentatie te doen.
        \cite{Li2010} stelt een techniek voor die begint met het detecteren van verticale en horizontale lijn segmenten. Dit doen ze door eerst een Canny edge detector\cite{Canny} toe te passen en vervolgens een line fitting.
        Een zelf geleerde \gls{svm} classifier verdeeld alle lijnsegmenten in 2 categorie\"{e}n namelijk horizontaal en verticaal. De vluchtlijnen van de gang worden hierbij onderverdeeld in de horizontale categorie.
        Alle lijnstukken krijgen een score via een reeks van operaties waarna enkel de beste lijnen bijgehouden worden. Op basis van de kleur van de vlakken tussen de lijnstukken kan een segmentatie gemaakt worden.
        Dit geeft een resultaat waarbij de vloer meestal een mooi homogeen geheel is, maar de muren worden in meerdere vlakken gesegmenteerd door eventuele kleurverschillen en objecten aan de muur.
        
        Een andere manier om de vloer te segmenteren is voorgesteld in~\cite{Rodriguez-Telles2013}. Zij doen een superpixel segmentatie volgens het SLIC algoritme~\cite{slic}, vervolgens bekijken ze de randen van de superpixels.
        Na observaties blijkt dat de randen van superpixels onregelmatig worden bij objectovergangen. Door het aanduiden van een paar vloerpixels kan hun algoritme superpixels aanduiden die tot de vloer behoren.
        Deze aanpak geeft een goede schatting van vrije ruimte op de vloer, maar is minder bruikbaar voor segmentatie van muren.

        Een meer recente technologie om afbeeldingen te segmenteren is gebruik te maken van een \gls{cnn}. Het netwerk voor segmentatie is verschillend van een traditioneel \gls{cnn} voor bijvoorbeeld object detectie.
        Een voorbeeld van een segmentatienetwerk is te zien in figuur~\ref{fig:segnet_cnn}.

        \begin{figure}[!hb]
            \centering
            \includegraphics[width=0.75\linewidth]{segnet.png}
            \caption{Het SegNet~\cite{Badrinarayanan} segmentatie netwerk.}
            \label{fig:segnet_cnn}
        \end{figure}

        Het segmentatienetwerk SegNet~\cite{Badrinarayanan} is een combinatie van convolutielagen en pooling layers, er zijn geen fully connected layers aanwezig zoals het geval is bij een classificatie netwerk.
        De bedoeling van het SegNet netwerk is om als output opnieuw een afbeelding te genereren, daarom zijn de lagen opgebouwd als een zandloper, op deze manier is de output even groot als de oorspronkelijke afbeelding.
        Een segmentatienetwerk wordt getraind op gelijkaardige manier aan een traditioneel \gls{cnn} met als verschil dat de labeling gebeurd op pixelbasis aangezien de output even groot is als de input van het systeem.
        De output van het systeem is een per pixel gelabelde afbeelding afhankelijk van het aantal classen waarmee het systeem getraind is.

        Het SegNet netwerk is getraind op de SUN RGB-D~\cite{Song_2015_CVPR} dataset. Deze dataset bevat een groot aantal indoor scenes, waarbij er onder andere segmentatie klassen zijn voor muren, vloeren en plafonds.
        De training is gebeurd met enkel de \gls{rgb} gegevens van de dataset. Deze trainingsdata zou uiteraard nuttig kunnen zijn voor dit onderzoek.
